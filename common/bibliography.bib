@INPROCEEDINGS{Pythia,
  author={Litou, Iouliana and Kalogeraki, Vana},
  booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Pythia: A System for Online Topic Discovery of Social Media Posts}, 
  year={2017},
  volume={},
  number={},
  pages={2497-2500},
  doi={10.1109/ICDCS.2017.289}
}

@misc{twitter-rec,
	title = {Twitter's {Recommendation} {Algorithm}},
	url = {https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm},
	abstract = {Twitter aims to deliver you the best of what's happening in the world right now. This blog is an introduction to how the algorithm selects Tweets for your timeline.},
	language = {en\_us},
	urldate = {2023-04-22},
	author = {Developers, Twitter},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\NFLPUZ2J\\twitter-recommendation-algorithm.html:text/html},
}

@article{DeepShortText,
  author       = {Jindong Chen and
                  Yizhou Hu and
                  Jingping Liu and
                  Yanghua Xiao and
                  Haiyun Jiang},
  title        = {Deep Short Text Classification with Knowledge Powered Attention},
  journal      = {CoRR},
  volume       = {abs/1902.08050},
  year         = {2019},
  url          = {http://arxiv.org/abs/1902.08050},
  eprinttype    = {arXiv},
  eprint       = {1902.08050},
  timestamp    = {Tue, 21 May 2019 18:03:39 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1902-08050.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{collatt,
title = {Collective attention in the age of (mis)information},
journal = {Computers in Human Behavior},
volume = {51},
pages = {1198-1204},
year = {2015},
note = {Computing for Human Learning, Behaviour and Collaboration in the Social and Mobile Networks Era},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215000382},
author = {Delia Mocanu and Luca Rossi and Qian Zhang and Marton Karsai and Walter Quattrociocchi},
keywords = {Misinformation, Collective narratives, Online social network},
abstract = {In this work we study, on a sample of 2.3million individuals, how Facebook users consumed different information at the edge of political discussion and news during the last Italian electoral competition. Pages are categorized, according to their topics and the communities of interests they pertain to, in (a) alternative information sources (diffusing topics that are neglected by science and main stream media); (b) online political activism; and (c) main stream media. We show that attention patterns are similar despite the different qualitative nature of the information, meaning that unsubstantiated claims (mainly conspiracy theories) reverberate for as long as other information. Finally, we classify users according to their interaction patterns among the different topics and measure how they responded to the injection of 2788 false information. Our analysis reveals that users which are prominently interacting with conspiracists information sources are more prone to interact with intentional false claims.}
}

@ARTICLE{echo-chambers,
  title    = "The echo chamber effect on social media",
  author   = "Cinelli, Matteo and De Francisci Morales, Gianmarco and Galeazzi,
              Alessandro and Quattrociocchi, Walter and Starnini, Michele",
  abstract = "Social media may limit the exposure to diverse perspectives and
              favor the formation of groups of like-minded users framing and
              reinforcing a shared narrative, that is, echo chambers. However,
              the interaction paradigms among users and feed algorithms greatly
              vary across social media platforms. This paper explores the key
              differences between the main social media platforms and how they
              are likely to influence information spreading and echo chambers'
              formation. We perform a comparative analysis of more than 100
              million pieces of content concerning several controversial topics
              (e.g., gun control, vaccination, abortion) from Gab, Facebook,
              Reddit, and Twitter. We quantify echo chambers over social media
              by two main ingredients: 1) homophily in the interaction networks
              and 2) bias in the information diffusion toward like-minded
              peers. Our results show that the aggregation of users in
              homophilic clusters dominate online interactions on Facebook and
              Twitter. We conclude the paper by directly comparing news
              consumption on Facebook and Reddit, finding higher segregation on
              Facebook.",
  journal  = "Proc Natl Acad Sci U S A",
  volume   =  118,
  number   =  9,
  month    =  mar,
  year     =  2021,
  address  = "United States",
  keywords = "echo chambers; information spreading; polarization; social media",
  language = "en"
}

@book{kb,
  title={The logic of knowledge bases},
  author={Levesque, Hector J and Lakemeyer, Gerhard},
  year={2001},
  publisher={MIT Press}
}


@misc{noauthor_wikipedia_nodate,
	title = {Wikipedia {API} — {Wikipedia} {Python} {API} 0.5.8 documentation},
	url = {https://wikipedia-api.readthedocs.io/en/latest/README.html},
	urldate = {2023-05-01},
	file = {Wikipedia API — Wikipedia Python API 0.5.8 documentation:C\:\\Users\\jfitz\\Zotero\\storage\\99VT42DT\\README.html:text/html},
}



@article{vangrad,
  title={The vanishing gradient problem during learning recurrent neural nets and problem solutions},
  author={Hochreiter, Sepp},
  journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume={6},
  number={02},
  pages={107--116},
  year={1998},
  publisher={World Scientific}
}

@article{misinfspread,
title = {Minimizing the spread of misinformation in online social networks: A survey},
journal = {Journal of Network and Computer Applications},
volume = {186},
pages = {103094},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103094},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001168},
author = {Ahmad Zareie and Rizos Sakellariou},
keywords = {Social networks, Misinformation spread minimization, Influence minimization, Diffusion models},
abstract = {Online social networks provide an opportunity to spread messages and news fast and widely. One may appreciate the quick spread of legitimate news and messages but misinformation can also be spread quickly and may raise concerns, questioning reliability and trust in such networks. As a result, detecting misinformation and containing its spread has become a hot topic in social network analysis. When misinformation is detected, some actions may be necessary to reduce its propagation and impact on the network. Such actions aim to minimize the number of users influenced by misinformation. This paper reviews approaches for solving this problem of minimizing spread of misinformation in social networks and proposes a taxonomy of different methods.}
}

@ARTICLE{nielson,
  author={Nielsen, J.},
  journal={Computer}, 
  title={The usability engineering life cycle}, 
  year={1992},
  volume={25},
  number={3},
  pages={12-22},
  doi={10.1109/2.121503}}

@book{git,
  title={Version Control with Git: Powerful tools and techniques for collaborative software development},
  author={Loeliger, Jon and McCullough, Matthew},
  year={2012},
  publisher={" O'Reilly Media, Inc."}
}

@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@Inbook{rnn-grad,
author="Graves, Alex",
title="Long Short-Term Memory",
bookTitle="Supervised Sequence Labelling with Recurrent Neural Networks",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="37--45",
abstract="As discussed in the previous chapter, an important benefit of recurrent neural networks is their ability to use contextual information when mapping between input and output sequences. Unfortunately, for standard RNN architectures, the range of context that can be in practice accessed is quite limited. The problem is that the influence of a given input on the hidden layer, and therefore on the network output, either decays or blows up exponentially as it cycles around the network's recurrent connections. This effect is often referred to in the literature as the vanishing gradient problem (Hochreiter, 1991; Hochreiter et al., 2001a; Bengio et al., 1994). The vanishing gradient problem is illustrated schematically in Figure 4.1",
isbn="978-3-642-24797-2",
doi="10.1007/978-3-642-24797-2_4",
url="https://doi.org/10.1007/978-3-642-24797-2_4"
}


@inproceedings{rnn-seq,
author = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
title = {Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143891},
doi = {10.1145/1143844.1143891},
abstract = {Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {369–376},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}


@misc{developers_counting_nodate,
	title = {Counting characters},
	url = {https://developer.twitter.com/en/docs/counting-characters},
	language = {en},
	urldate = {2023-04-29},
	author = {Developers, Twitter},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\AKQNWBX3\\counting-characters.html:text/html},
}


@article{mahesh2020machine,
  title={Machine learning algorithms-a review},
  author={Mahesh, Batta},
  journal={International Journal of Science and Research (IJSR).[Internet]},
  volume={9},
  pages={381--386},
  year={2020}
}

@article{misinf,
    doi = {10.1371/journal.pone.0118093},
    author = {Bessi, Alessandro AND Coletto, Mauro AND Davidescu, George Alexandru AND Scala, Antonio AND Caldarelli, Guido AND Quattrociocchi, Walter},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Science vs Conspiracy: Collective Narratives in the Age of Misinformation},
    year = {2015},
    month = {02},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0118093},
    pages = {1-17},
    abstract = {The large availability of user provided contents on online social media facilitates people aggregation around shared beliefs, interests, worldviews and narratives. In spite of the enthusiastic rhetoric about the so called collective intelligence unsubstantiated rumors and conspiracy theories—e.g., chemtrails, reptilians or the Illuminati—are pervasive in online social networks (OSN). In this work we study, on a sample of 1.2 million of individuals, how information related to very distinct narratives—i.e. main stream scientific and conspiracy news—are consumed and shape communities on Facebook. Our results show that polarized communities emerge around distinct types of contents and usual consumers of conspiracy news result to be more focused and self-contained on their specific contents. To test potential biases induced by the continued exposure to unsubstantiated rumors on users’ content selection, we conclude our analysis measuring how users respond to 4,709 troll information—i.e. parodistic and sarcastic imitation of conspiracy theories. We find that 77.92% of likes and 80.86% of comments are from users usually interacting with conspiracy stories.},
    number = {2},

}

@misc{sklearn-split,
	title = {sklearn.model\_selection.train\_test\_split},
	url = {https://scikit-learn/stable/modules/generated/sklearn.model_selection.train_test_split.html},
	abstract = {Examples using sklearn.model\_selection.train\_test\_split: Release Highlights for scikit-learn 0.24 Release Highlights for scikit-learn 0.24 Release Highlights for scikit-learn 0.23 Release Highlight...},
	language = {en},
	urldate = {2023-04-23},
	journal = {scikit-learn},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\ZY7E8HAE\\sklearn.model_selection.train_test_split.html:text/html},
}


@misc{pandas-dummies,
	title = {pandas.get\_dummies — pandas 2.0.0 documentation},
	url = {https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html},
	urldate = {2023-04-23},
	file = {pandas.get_dummies — pandas 2.0.0 documentation:C\:\\Users\\jfitz\\Zotero\\storage\\BA67UTHZ\\pandas.get_dummies.html:text/html},
}


@misc{tensorflow_hub,
	title = {{TensorFlow} {Hub}},
	url = {https://www.tensorflow.org/hub},
	abstract = {TensorFlow Hub is a repository of trained machine learning models ready for fine-tuning and deployable anywhere. Reuse trained models like BERT and Faster R-CNN with just a few lines of code.},
	language = {en},
	urldate = {2023-05-01},
	journal = {TensorFlow},
}


@misc{keras,
	title = {Keras documentation: {Keras} {API} reference},
	shorttitle = {Keras documentation},
	url = {https://keras.io/api/},
	abstract = {Keras documentation},
	language = {en},
	urldate = {2023-05-01},
	author = {Team, Keras},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\ADXTNC6I\\api.html:text/html},
}



@misc{tensorflow,
	title = {{TensorFlow}},
	url = {https://www.tensorflow.org/},
	abstract = {An end-to-end open source machine learning platform for everyone. Discover TensorFlow's flexible ecosystem of tools, libraries and community resources.},
	language = {en},
	urldate = {2023-05-01},
	journal = {TensorFlow},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\7C46BAZ8\\www.tensorflow.org.html:text/html},
}


@misc{tftokenizer,
    title = {tf.keras.preprocessing.text.{Tokenizer} {\textbar} {TensorFlow} v2.12.0},
    url = {https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer%7D},
    abstract = {Text tokenization utility class.},
    language = {en},
    urldate = {2023-04-14},
    journal = {TensorFlow},
    author = {Tensorflow, Devvelopers},
    file = {Snapshot:C:\Users\jfitz\Zotero\storage\24X366EE\Tokenizer.html:text/html},
}

@article{multi-head-pros,
  author       = {Liyuan Liu and
                  Jialu Liu and
                  Jiawei Han},
  title        = {Multi-head or Single-head? An Empirical Comparison for Transformer
                  Training},
  journal      = {CoRR},
  volume       = {abs/2106.09650},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.09650},
  eprinttype    = {arXiv},
  eprint       = {2106.09650},
  timestamp    = {Tue, 29 Jun 2021 16:55:04 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-09650.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{twitter_developer_nodate,
    title = {Developer account support},
    url = {https://developer.twitter.com/en/support/twitter-api/developer-account%7D},
    abstract = {Get support using your developer account and developer portal here.},
    language = {en},
    urldate = {2023-04-08},
    accessdate = {2023-04-08},
    author = {Twitter, Developers},
    file = {Snapshot:C:\Users\jfitz\Zotero\storage\C6B6QTJ8\developer-account.html:text/html},
}

@misc{hug-rob,
	title = {{RoBERTa}},
	url = {https://huggingface.co/docs/transformers/model_doc/roberta},
	abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-05-01},
}

@misc{huggingface,
	title = {huggingface ({Hugging} {Face})},
	url = {https://huggingface.co/huggingface},
	abstract = {The AI community building the future.},
	urldate = {2023-05-01},
	month = mar,
	year = {2023},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\UE6II3YA\\huggingface.html:text/html},
}



@misc{pytest,
	title = {pytest {\textbar} {Read} the {Docs}},
	url = {https://readthedocs.org/projects/pytest/},
	urldate = {2023-05-01},
}


@misc{pyqt,
	title = {{PyQt5} {Reference} {Guide} — {PyQt} {Documentation} v5.15.4},
	url = {https://www.riverbankcomputing.com/static/Docs/PyQt5/},
	urldate = {2023-05-01},
	file = {PyQt5 Reference Guide — PyQt Documentation v5.15.4:C\:\\Users\\jfitz\\Zotero\\storage\\YUYG3QAQ\\PyQt5.html:text/html},
}


@misc{moviepy,
	title = {User {Guide} — {MoviePy} 1.0.2 documentation},
	url = {https://zulko.github.io/moviepy/},
	urldate = {2023-05-01},
	file = {User Guide — MoviePy 1.0.2 documentation:C\:\\Users\\jfitz\\Zotero\\storage\\XP9RGMGC\\moviepy.html:text/html},
}


@misc{transformers,
    title = {Transformers},
    url = {https://huggingface.co/docs/transformers/index%7D},
    abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
    urldate = {2023-04-08},
    author = {Huggingface, Developers},
    note = {V4.27.2},
    file = {Snapshot:C:\Users\jfitz\Zotero\storage\UEEXCUII\index.html:text/html},
}
@misc{praw,
    title = {{PRAW}: {The} {Python} {Reddit} {API} {Wrapper} — {PRAW} 7.7.0 documentation},
    url = {https://praw.readthedocs.io/en/stable/%7D},
    urldate = {2023-04-08},
    author = {Bryce Boe},
    file = {PRAW: The Python Reddit API Wrapper — PRAW 7.7.0 documentation:C:\Users\jfitz\Zotero\storage\T8AZF63R\stable.html:text/html},
}

@misc{wiki-api,
    title = {Wikipedia-{API}: {Python} {Wrapper} for {Wikipedia}},
    copyright = {MIT License},
    shorttitle = {Wikipedia-{API}},
    url = {https://github.com/martin-majlis/Wikipedia-API%7D},
    urldate = {2023-04-05},
    author = {Majlis, Martin},
    keywords = {API,, Communications - Email, Software Development - Libraries - Python Modules, Wikipedia,, wrapper},
    file = {Snapshot:C:\Users\jfitz\Zotero\storage\CBVYN5XM\Wikipedia-API.html:text/html},
}
@article{echo-chambers,
author = {Carlos Diaz Ruiz and Tomas Nilsson},
title ={Disinformation and Echo Chambers: How Disinformation Circulates on Social Media Through Identity-Driven Controversies},
journal = {Journal of Public Policy \& Marketing},
volume = {42},
number = {1},
pages = {18-35},
year = {2023},
doi = {10.1177/07439156221103852},

URL = { 
        https://doi.org/10.1177/07439156221103852
    
},
eprint = { 
        https://doi.org/10.1177/07439156221103852
    
}
,
    abstract = { This article investigates how disinformation circulates on social media as adversarial narratives embedded in identity-driven controversies. Empirically, the article reports on the flat Earth echo chamber on YouTube, a controversial group arguing that the earth is a plane, not a sphere. By analyzing how they weave their arguments, this study demonstrates that disinformation circulates through identity-based grievances. As grudges intensify, back-and-forth argumentation becomes a form of knowing that solidifies viewpoints. Moreover, the argument resists fact-checking because it stokes the contradictions of identity work through grievances (pathos) and group identification (ethos). The conceptual contribution proposes a two-phase framework for how disinformation circulates on social media. The first phase, “seeding,” is when malicious actors strategically insert deceptions by masquerading their legitimacy (e.g., fake news). The second phase, “echoing,” enlists participants to cocreate the contentious narratives that disseminate disinformation. A definition of disinformation is proposed: Disinformation is an adversarial campaign that weaponizes multiple rhetorical strategies and forms of knowing—including not only falsehoods but also truths, half-truths, and value-laden judgments—to exploit and amplify identity-driven controversies. Finally, the paper has implications for policy makers in handling the spread of disinformation on social media. }
}
@article{DBLP:journals/corr/abs-1907-11692,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  eprinttype = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Book{cambdict,
    publisher = {Cambridge University Press},
    author = {Topic.},
    title = {{Cambridge Advanced Learner's Dictionary & Thesaurus}},
    year = {n.d.},
}

@article{latentDirAll,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@Article{TopicTracking,
  author={Peng, Xian
  and Han, Chengyang
  and Ouyang, Fan
  and Liu, Zhi},
  title={Topic tracking model for analyzing student-generated posts in SPOC discussion forums},
  journal={International Journal of Educational Technology in Higher Education},
  year={2020},
  month={Sep},
  day={02},
  volume={17},
  number={1},
  pages={35},
  abstract={Due to an overwhelming amount of student-generated forum posts in small private online courses (SPOCs), students and instructors find it time-consuming and challenging to effectively navigate and track valuable information, such as the evolution of topics, emotional and behavioral changes in relation to topics. For solving this problem, this study analyzed plenty of discussion posts using an improved dynamic topic model, Time Information-Emotion Behavior Model (TI-EBTM). Time, emotion, and behavior characteristics were incorporated into the topic modeling process, which allowed for an overview of automatic tracking and understanding of temporal topic changes in SPOC discussion forums. The experiment on data from 30 SPOC courses showed that TI-EBTM outperformed other dynamic topic models and was effective in extracting prominent topics over time. Furthermore, we conducted an in-depth temporal topic analysis to investigate the utility of TI-EBTM in a case study. The results of the case study demonstrated that our methodology and analysis shed light on students' temporal focuses (i.e., the changes of topic intensity and topic content) and reflected the evolution of topics' emotional and behavioral tendencies. For example, students tended to express more negative emotions toward the topic about the method of data query by initiating the conversation at the end of the semester. The analytical results can provide instructors with valuable insights into the development of course forums and enable them to fine-tune course forums to suit students' requirements, which will subsequently be helpful in enhancing discussion interaction and students' learning experience.},
  issn={2365-9440},
  doi={10.1186/s41239-020-00211-4},
  url={https://doi.org/10.1186/s41239-020-00211-4}
}

@inproceedings{husby2012topic,
  title={Topic classification of blog posts using distant supervision},
  author={Husby, Stephanie and Barbosa, Denilson},
  booktitle={Proceedings of the Workshop on Semantic Analysis in Social Media},
  pages={28--36},
  year={2012}
}


@misc{instagram_how_nodate,
	title = {How {Instagram} determines which posts appear as suggested posts {\textbar} {Instagram} {Help} {Centre}},
	url = {https://help.instagram.com/381638392275939},
	urldate = {2022-10-12},
	journal = {How Instagram determines which posts appear as suggested posts},
	author = {Instagram},
	file = {How Instagram determines which posts appear as suggested posts | Instagram Help Centre:C\:\\Users\\jfitz\\Zotero\\storage\\WKICQT9W\\381638392275939.html:text/html},
}


@misc{BERTTopic,
	title = {bertopic: {BERTopic} performs topic {Modeling} with state-of-the-art transformer models.},
	copyright = {MIT License},
	shorttitle = {bertopic},
	url = {https://github.com/MaartenGr/BERTopic},
	urldate = {2023-04-23},
	author = {Grootendorst, Maarten P.},
	keywords = {bert,, embeddings, modeling,, nlp,, Scientific/Engineering, Scientific/Engineering - Artificial Intelligence, topic,},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\DEW6AILU\\bertopic.html:text/html},
}


@misc{LDAVis,
	title = {{pyLDAvis}: {Interactive} topic model visualization. {Port} of the {R} package.},
	copyright = {BSD License},
	shorttitle = {{pyLDAvis}},
	url = {https://github.com/bmabey/pyLDAvis},
	urldate = {2023-04-23},
	author = {Mabey, Ben},
	keywords = {data science,, visualization},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\IBWXCRGQ\\pyLDAvis.html:text/html},
}


@misc{gensimLDA,
	title = {Gensim: topic modelling for humans},
	shorttitle = {Gensim},
	url = {https://radimrehurek.com/gensim/models/ldamulticore.html},
	abstract = {Efficient topic modelling in Python},
	language = {en},
	urldate = {2023-04-23},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\ZX7J7WM2\\ldamulticore.html:text/html},
}


@article{recommenderSystems,
  title = {How do users interact with algorithm recommender systems? The interaction of users, algorithms, and performance},
  journal = {Computers in Human Behavior},
  volume = {109},
  pages = {106344},
  year = {2020},
  issn = {0747-5632},
  doi = {https://doi.org/10.1016/j.chb.2020.106344},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563220300984},
  author = {Donghee Shin},
  keywords = {Algorithm, News recommendation system, Algorithm heuristic, Algorithm user experience, User-centered algorithm},
  abstract = {Although algorithms have been widely used to deliver useful applications and services, it is unclear how users actually experience and interact with algorithm-driven services. This ambiguity is even more troubling in news recommendation algorithms, where thorny issues are complicated. This study investigates the user experience and usability of algorithms by focusing on users' cognitive process to understand how qualities/features are received and transformed into experiences and interaction. This work examines how users perceive and feel about issues in news recommendations and how they interact and engage with algorithm-recommended news. It proposes an algorithm experience model of news recommendation integrating the heuristic process of cognitive, affective, and behavioral factors. The underlying algorithm can affect in different ways the user's perception and trust of the system. The heuristic affect occurs when users' subjective feelings about transparency and accuracy act as a mental shortcut: users considered transparent and accurate systems convenient and useful. The mediating role of trust suggests that establishing algorithmic trust between users and NRS could enhance algorithm performance. The model illustrates the users' cognitive processes of perceptual judgment as well as the motivation behind user behaviors. The results highlight a link between news recommendation systems and user interaction, providing a clearer conceptualization of user-centered development and the evaluation of algorithm-based services.}
}


@misc{tokenizer-important,
	title = {Tokenizer},
	url = {https://huggingface.co/docs/transformers/main_classes/tokenizer},
	abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-05-01},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\2E5J2KH6\\tokenizer.html:text/html},
}


@misc{keras-tokenizer,
	title = {tf.keras.preprocessing.text.{Tokenizer} {\textbar} {TensorFlow} v2.12.0},
	url = {https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer},
	abstract = {Text tokenization utility class.},
	language = {en},
	urldate = {2023-04-23},
	journal = {TensorFlow},
}


@misc{wikiapi,
	title = {Wikipedia-{API}: {Python} {Wrapper} for {Wikipedia}},
	copyright = {MIT License},
	shorttitle = {Wikipedia-{API}},
	url = {https://github.com/martin-majlis/Wikipedia-API},
	urldate = {2023-04-23},
	author = {Majlis, Martin},
	keywords = {API,, Communications - Email, Software Development - Libraries - Python Modules, Wikipedia,, wrapper},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\76EW6VZ7\\Wikipedia-API.html:text/html},
}


@article{attention,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{snow,
  title={Learning syntactic patterns for automatic hypernym discovery},
  author={Snow, Rion and Jurafsky, Daniel and Ng, Andrew},
  journal={Advances in neural information processing systems},
  volume={17},
  year={2004}
}

@article{mediabiasmonitor,
  title={Media Bias Monitor: Quantifying Biases of Social Media News Outlets at Large-Scale},
  volume={12},
  url={https://ojs.aaai.org/index.php/ICWSM/article/view/15025},
  abstractNote={ &lt;p&gt; As Internet users increasingly rely on social media sites like Facebook and Twitter to receive news, they are faced with a bewildering number of news media choices. For example, thousands of Facebook pages today are registered and categorized as some form of news media outlets. Inferring the bias (or slant) of these media pages poses a difficult challenge for media watchdog organizations that traditionally rely on content analysis. In this paper, we explore a novel scalable methodology to accurately infer the biases of thousands of news sources on social media sites like Facebook and Twitter. Our key idea is to utilize their advertiser interfaces, that offer detailed insights into the demographics of the news source’s audience on the social media site. We show that the ideological (liberal or conservative) leaning of a news source can be accurately estimated by the extent to which liberals or conservatives are over-/under-represented among its audience. Additionally, we show how biases in a news source’s audience demographics, along the lines of race, gender, age, national identity, and income, can be used to infer more fine-grained biases of the source, such as social vs. economic vs. nationalistic conservatism. Finally, we demonstrate the scalability of our approach by building and publicly deploying a system, called &quot;Media Bias Monitor&quot;, which makes the biases in audience demographics for over 20,000 news outlets on Facebook transparent to any Internet user. &lt;/p&gt; },
  number={1},
  journal={Proceedings of the International AAAI Conference on Web and Social Media},
  author={Ribeiro, Filipe and Henrique, Lucas and Benevenuto, Fabricio and Chakraborty, Abhijnan and Kulshrestha, Juhi and Babaei, Mahmoudreza and Gummadi, Krishna},
  year={2018},
  month={Jun.}
}

@Article{searchbiasquant,
  author={Kulshrestha, Juhi
  and Eslami, Motahhare
  and Messias, Johnnatan
  and Zafar, Muhammad Bilal
  and Ghosh, Saptarshi
  and Gummadi, Krishna P.
  and Karahalios, Karrie},
  title={Search bias quantification: investigating political bias in social media and web search},
  journal={Information Retrieval Journal},
  year={2019},
  month={Apr},
  day={01},
  volume={22},
  number={1},
  pages={188-227},
  abstract={Users frequently use search systems on the Web as well as online social media to learn about ongoing events and public opinion on personalities. Prior studies have shown that the top-ranked results returned by these search engines can shape user opinion about the topic (e.g., event or person) being searched. In case of polarizing topics like politics, where multiple competing perspectives exist, the political bias in the top search results can play a significant role in shaping public opinion towards (or away from) certain perspectives. Given the considerable impact that search bias can have on the user, we propose a generalizable search bias quantification framework that not only measures the political bias in ranked list output by the search system but also decouples the bias introduced by the different sources---input data and ranking system. We apply our framework to study the political bias in searches related to 2016 US Presidential primaries in Twitter social media search and find that both input data and ranking system matter in determining the final search output bias seen by the users. And finally, we use the framework to compare the relative bias for two popular search systems---Twitter social media search and Google web search---for queries related to politicians and political events. We end by discussing some potential solutions to signal the bias in the search results to make the users more aware of them.},
  issn={1573-7659},
  doi={10.1007/s10791-018-9341-2},
  url={https://doi.org/10.1007/s10791-018-9341-2}
}


@misc{keras_ocr,
	title = {keras-ocr — keras\_ocr documentation},
	url = {https://keras-ocr.readthedocs.io/en/latest/},
	urldate = {2023-05-01},
}



@misc{academic_acc,
	title = {{GET} /2/tweets/search/all},
	url = {https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all},
	language = {en},
	urldate = {2023-05-01},
	file = {Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\IKVQVJ9P\\get-tweets-search-all.html:text/html},
}


@misc{requests,
	title = {Requests: {HTTP} for {Humans}™ — {Requests} 2.29.0 documentation},
	url = {https://requests.readthedocs.io/en/latest/},
	urldate = {2023-05-01},
	file = {Requests\: HTTP for Humans™ — Requests 2.29.0 documentation:C\:\\Users\\jfitz\\Zotero\\storage\\IBQ5C7JM\\latest.html:text/html},
}


@misc{tweepy,
	title = {Tweepy {Documentation} — tweepy 4.14.0 documentation},
	url = {https://docs.tweepy.org/en/stable/},
	urldate = {2023-05-01},
	file = {Tweepy Documentation — tweepy 4.14.0 documentation:C\:\\Users\\jfitz\\Zotero\\storage\\KEBNYWPS\\stable.html:text/html},
}


@article{retweetspoliticallean,
  title={Quantifying Political Leaning from Tweets and Retweets},
  volume={7},
  url={https://ojs.aaai.org/index.php/ICWSM/article/view/14422},
  abstractNote={ &lt;p&gt; Media outlets and pundits have been quick to embrace online social networks to disseminate their own opinions. But pundits’ opinions and news coverage are often marked by a clear political bias, as widely evidenced during the fiercely contested&lt;br /&gt;2012 U.S. presidential elections. Given the wide availability of such data from sites like Twitter, a natural question is whether we can quantify the political leanings of media outlets using OSN data. In this work, by drawing a correspondence between tweeting and retweeting behavior, we formulate political leaning estimation as an ill-posed linear inverse problem. The result is a simple and scalable approach that does not require explicit knowledge of the network topology. We evaluate our method with a dataset of 119 million election-related tweets collected from April to November, and use it to study the political leaning of prominent tweeters and media sources. &lt;/p&gt; },
  number={1},
  journal={Proceedings of the International AAAI Conference on Web and Social Media},
  author={Wong, Felix Ming Fai and Tan, Chee Wei and Sen, Soumya and Chiang, Mung},
  year={2021},
  month={Aug.},
  pages={640-649}
}

@inproceedings{bertmodelling,
  title={Identifying topics of scientific articles with BERT-based approaches and topic modeling},
  author={Glazkova, Anna},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  pages={98--105},
  year={2021},
  organization={Springer}
}


@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2022-11-20},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\jfitz\\Zotero\\storage\\NYSZCJRC\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jfitz\\Zotero\\storage\\7ISNQ5HK\\1810.html:text/html},
}

@article{sarica2021stopwords,
  title={Stopwords in technical language processing},
  author={Sarica, Serhad and Luo, Jianxi},
  journal={Plos one},
  volume={16},
  number={8},
  pages={e0254937},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{bert,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  journal      = {CoRR},
  volume       = {abs/1810.04805},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.04805},
  eprinttype    = {arXiv},
  eprint       = {1810.04805},
  timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}